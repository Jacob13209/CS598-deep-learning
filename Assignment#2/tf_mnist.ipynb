{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment *2* - CS598 - Deep Learning \n",
    "\n",
    "__Tensorflow with MNIST__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries \n",
    "\n",
    "For this homework, it is using tensorflow for the MNIST problem. Based on the example in the textbook, libraries being used are mainly from tensorflow, including mnist dataset and layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Check the version of tensorflow to verify it will work with the examople from the textbook (1.14.0)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.layers as layers # for fully_connected layers \n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/homework2/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSz = 100\n",
    "learningRate = 0.5\n",
    "epoches = 10 \n",
    "\n",
    "# calculate number of batches for training/test data\n",
    "trainingBatches = int(len(mnist.train.labels) / batchSz) * epoches \n",
    "testBatches = int(len(mnist.test.labels) / batchSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single layer implementation w/o layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "W = tf.Variable(tf.random_normal([784, 10],stddev=.1))\n",
    "b = tf.Variable(tf.random_normal([10],stddev=.1))\n",
    "\n",
    "img = tf.placeholder(tf.float32, [batchSz,784])\n",
    "ans = tf.placeholder(tf.float32, [batchSz, 10])\n",
    "\n",
    "prbs = tf.nn.softmax(tf.matmul(img, W) + b)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Two layers implementation w/o layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "W1 = tf.Variable(tf.random_normal([784,256], stddev=.1))\n",
    "b1 = tf.Variable(tf.random_normal([256], stddev=.1))\n",
    "W2 = tf.Variable(tf.random_normal([256,10], stddev=.1))\n",
    "b2 = tf.Variable(tf.random_normal([10], stddev=.1))\n",
    "\n",
    "img = tf.placeholder(tf.float32, [batchSz,784])\n",
    "ans = tf.placeholder(tf.float32, [batchSz, 10])\n",
    "\n",
    "l1_output = tf.matmul(img, W1) + b1\n",
    "l1_output = tf.nn.relu(l1_output)\n",
    "\n",
    "prbs = tf.nn.softmax(tf.matmul(l1_output, W2) + b2)\n",
    "\"\"\"\n",
    "pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Two layers implementation with fully_connected layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.placeholder(tf.float32, [batchSz,784])\n",
    "ans = tf.placeholder(tf.float32, [batchSz, 10])\n",
    "\n",
    "l1_output = layers.fully_connected(img, 756) # inputs, num_outpts\n",
    "\n",
    "prbs = layers.fully_connected(l1_output, 10, tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xEnt = tf.reduce_mean(-tf.reduce_sum(ans * tf.log(prbs), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learningRate).minimize(xEnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCorrect= tf.equal(tf.argmax(prbs,1), tf.argmax(ans,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(numCorrect, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Train Accuracy: 0.14\n",
      "Batch: 100, Train Accuracy: 0.91\n",
      "Batch: 200, Train Accuracy: 0.95\n",
      "Batch: 300, Train Accuracy: 0.96\n",
      "Batch: 400, Train Accuracy: 0.94\n",
      "Batch: 500, Train Accuracy: 0.94\n",
      "Batch: 600, Train Accuracy: 0.96\n",
      "Batch: 700, Train Accuracy: 0.96\n",
      "Batch: 800, Train Accuracy: 0.92\n",
      "Batch: 900, Train Accuracy: 0.99\n",
      "Batch: 1000, Train Accuracy: 0.96\n",
      "Batch: 1100, Train Accuracy: 0.96\n",
      "Batch: 1200, Train Accuracy: 1.0\n",
      "Batch: 1300, Train Accuracy: 0.97\n",
      "Batch: 1400, Train Accuracy: 0.95\n",
      "Batch: 1500, Train Accuracy: 0.97\n",
      "Batch: 1600, Train Accuracy: 0.98\n",
      "Batch: 1700, Train Accuracy: 1.0\n",
      "Batch: 1800, Train Accuracy: 0.99\n",
      "Batch: 1900, Train Accuracy: 1.0\n",
      "Batch: 2000, Train Accuracy: 0.99\n",
      "Batch: 2100, Train Accuracy: 1.0\n",
      "Batch: 2200, Train Accuracy: 1.0\n",
      "Batch: 2300, Train Accuracy: 1.0\n",
      "Batch: 2400, Train Accuracy: 0.99\n",
      "Batch: 2500, Train Accuracy: 1.0\n",
      "Batch: 2600, Train Accuracy: 0.97\n",
      "Batch: 2700, Train Accuracy: 0.99\n",
      "Batch: 2800, Train Accuracy: 0.99\n",
      "Batch: 2900, Train Accuracy: 0.99\n",
      "Batch: 3000, Train Accuracy: 0.99\n",
      "Batch: 3100, Train Accuracy: 1.0\n",
      "Batch: 3200, Train Accuracy: 1.0\n",
      "Batch: 3300, Train Accuracy: 0.98\n",
      "Batch: 3400, Train Accuracy: 0.99\n",
      "Batch: 3500, Train Accuracy: 0.99\n",
      "Batch: 3600, Train Accuracy: 1.0\n",
      "Batch: 3700, Train Accuracy: 1.0\n",
      "Batch: 3800, Train Accuracy: 1.0\n",
      "Batch: 3900, Train Accuracy: 0.99\n",
      "Batch: 4000, Train Accuracy: 1.0\n",
      "Batch: 4100, Train Accuracy: 0.99\n",
      "Batch: 4200, Train Accuracy: 0.99\n",
      "Batch: 4300, Train Accuracy: 1.0\n",
      "Batch: 4400, Train Accuracy: 0.99\n",
      "Batch: 4500, Train Accuracy: 1.0\n",
      "Batch: 4600, Train Accuracy: 1.0\n",
      "Batch: 4700, Train Accuracy: 1.0\n",
      "Batch: 4800, Train Accuracy: 1.0\n",
      "Batch: 4900, Train Accuracy: 1.0\n",
      "Batch: 5000, Train Accuracy: 1.0\n",
      "Batch: 5100, Train Accuracy: 1.0\n",
      "Batch: 5200, Train Accuracy: 0.99\n",
      "Batch: 5300, Train Accuracy: 1.0\n",
      "Batch: 5400, Train Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(trainingBatches):\n",
    "    imgs, anss = mnist.train.next_batch(batchSz)\n",
    "    # textbook p.38, python's combining computation\n",
    "    train_acc,ignore= sess.run([accuracy,train], feed_dict={img: imgs, ans: anss})\n",
    "    if i % 100 == 0:\n",
    "        print(\"Batch: %r, Train Accuracy: %r\" % (i, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9821000093221665\n"
     ]
    }
   ],
   "source": [
    "sumAcc=0\n",
    "for i in range(testBatches):\n",
    "    imgs, anss= mnist.test.next_batch(batchSz)\n",
    "    sumAcc+=sess.run(accuracy, feed_dict={img: imgs, ans: anss})\n",
    "print(\"Test Accuracy: %r\" % (sumAcc/testBatches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "*Introduction to Deep Learning by Eugene Charniak*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
